import os
import logging.config
import yaml
import json
import pickle
#
import torch
from torchvision.utils import make_grid
#
from . import pytorch_ssim
from .flowlib import batch_flow_to_image


def get_dir(directory):
    """
    get the directory, if no such directory, then make it.

    @param directory: The new directory.
    """

    if not os.path.exists(directory):
        os.makedirs(directory)

    return directory

# 读-改-写到另一处
def set_yaml_log_root(conf_in, conf_out, log_root, tag=None):
    print(conf_in)
    if tag is not None:
        info_log_name = '{}_info.log'.format(tag)
        error_log_name = '{}_error.log'.format(tag)
    else:
        info_log_name = 'info.log'
        error_log_name = 'error.log'
    #
    with open(conf_in, "r") as fp:
        config = yaml.load(fp)
    #
    config['handlers']['info_file_handler']['filename'] = \
        os.path.join(log_root, info_log_name)
    config['handlers']['error_file_handler']['filename'] = \
        os.path.join(log_root, error_log_name)
    #
    with open(conf_out, "w+") as fp:
        yaml.safe_dump(config, fp, allow_unicode=True, default_flow_style=False)

    return conf_out

def get_logger(conf_in, log_save_root=None, tag=None):
    conf_out = os.path.join(log_save_root, "{}.yaml".format(tag))
    if os.path.exists(conf_in):
        if log_save_root is not None:
            # update yaml
            conf_out = set_yaml_log_root(conf_in, conf_out, log_save_root, tag)
        #
        with open(conf_out, "r") as fp:
            config = yaml.load(fp)
            logging.config.dictConfig(config)
    else:
        print("{} not exist".format(conf_in))
        exit()
    #
    logger = logging.getLogger()
    return logger

def log10(t):
    """
    Calculates the base-10 log of each element in t.
    @param t: The tensor from which to calculate the base-10 log.
    @return: A tensor with the base-10 log of each element in t.
    """
    # numerator = torch.log(t)
    # denominator = torch.log(torch.FloatTensor([10.]))
    # return numerator / denominator
    return torch.log10(t)

#for [B,C,W,H]
def bgr_gray(input_tensor):
    B=input_tensor[:,0].view(input_tensor.size()[0],1,input_tensor.size()[2],input_tensor.size()[3])
    G=input_tensor[:,1].view(input_tensor.size()[0],1,input_tensor.size()[2],input_tensor.size()[3])
    R=input_tensor[:,2].view(input_tensor.size()[0],1,input_tensor.size()[2],input_tensor.size()[3])
    gray_tensor=B*0.114+G*0.587+R*0.299
    return gray_tensor

def diff_mask(gen_frames, gt_frames, min_value=-1, max_value=1):
    # normalize to [0, 1]
    delta = max_value - min_value
    gen_frames = (gen_frames - min_value) / delta
    gt_frames = (gt_frames - min_value) / delta

    gen_gray_frames = bgr_gray(gen_frames)
    gt_gray_frames = bgr_gray(gt_frames)

    diff = torch.abs(gen_gray_frames - gt_gray_frames)
    return diff

def mse_error(gen_frames, gt_frames):
    """
    Computes the Peak Signal to Noise Ratio error between the generated images and the ground
    truth images.

    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the
                       generator model.
    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for
                      each frame in gen_frames.

    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the
             batch.
    """
    loss = torch.nn.MSELoss()
    return loss(gt_frames, gen_frames) * 16 * 16

def ssim_error(gen_frames, gt_frames):
    """
    Computes the Peak Signal to Noise Ratio error between the generated images and the ground
    truth images.

    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the
                       generator model.
    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for
                      each frame in gen_frames.

    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the
             batch.
    """
    # pixel value is in [-1,1] (normalize过)
    ssim_loss = pytorch_ssim.SSIM(window_size=11)
    return ssim_loss(gen_frames, gt_frames)

def psnr_error(gen_frames, gt_frames):
    """
    Computes the Peak Signal to Noise Ratio error between the generated images and the ground
    truth images.
    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the
                       generator model.
    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for
                      each frame in gen_frames.
    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the
             batch.
    """
    shape = list(gen_frames.shape)
    num_pixels = (shape[1] * shape[2] * shape[3])
    gt_frames = (gt_frames + 1.0) / 2.0
    gen_frames = (gen_frames + 1.0) / 2.0
    square_diff = (gt_frames - gen_frames)**2

    batch_errors = 10 * log10(1. / ((1. / num_pixels) * torch.sum(square_diff, [1, 2, 3]))) # max == 1
    return torch.mean(batch_errors)

# code borrowed from https://github.com/NVIDIA/flownet2-pytorch/blob/master/losses.py
def epe_error(input_flow, target_flow):
    return torch.norm(target_flow-input_flow,p=2,dim=1).mean()

# def set_logger(log_path):
#     """Set the logger to log info in terminal and file `log_path`.
#     In general, it is useful to have a logger so that every output to the terminal is saved
#     in a permanent file. Here we save it to `model_dir/train.log`.
#     Example:
#     ```
#     logging.info("Starting training...")
#     ```
#     Args:
#         log_path: (string) where to log
#     """
#     logger = logging.getLogger()
#     logger.setLevel(logging.INFO)
#
#     if not logger.handlers:
#         # Logging to a file
#         file_handler = logging.FileHandler(log_path)
#         file_format = logging.Formatter('%(asctime)s:%(levelname)s: %(message)s')
#         file_handler.setFormatter(file_format)
#         logger.addHandler(file_handler)
#
#         # Logging to console
#         stream_handler = logging.StreamHandler()
#         stream_format = logging.Formatter('%(message)s')
#         stream_handler.setFormatter(stream_format)
#         logger.addHandler(stream_handler)

# 保存 model single ckpt
def saver(model_state_dict, model_path, step, logger):
    # total_models=glob.glob(model_path+'*')
    # if len(total_models)>=max_to_save:
    #     total_models.sort()
    #     os.remove(total_models[0])
    save_file = os.path.join(model_path, 'step_{}.pth'.format(str(step + 1).zfill(6)))
    torch.save(model_state_dict, save_file)
    logger.info('model {} save successfully!'.format(save_file))

# 从单文件load ckpt
def loader(model, model_dir, logger):
    ckpt_list = os.listdir(model_dir) # 注意一个 bug, os.listdir(xxx).sort() 返回None
    ckpt_list.sort() # 所以只能这样写
    print("model_dir: ", model_dir, ckpt_list)
    ckpt_path_last = os.path.join(model_dir, ckpt_list[-1])
    assert ckpt_path_last != None, \
        "ckpt_path_last = None"
    model.load_state_dict(torch.load(ckpt_path_last,map_location="cuda:0"))
    g_step = int(ckpt_path_last.split('_')[-1].split('.')[0]) # step_020001.pth
    logger.info('load model {} successfully!'.format(ckpt_path_last))
    #
    return model, g_step

# 从多文件 load ckpt 然后拼接 fixed params 专门 finetune某一部分
def loader_rgb_op_branch_v1(model, rgb_model_path, op_model_path, logger):
    # 获取现有模型的参数字典
    rgb_pretrained_dict = torch.load(rgb_model_path, map_location="cuda:0")
    op_pretrained_dict = torch.load(op_model_path, map_location="cuda:0")
    model_dict = model.state_dict()
    #
    # 获取两个模型相同网络层的参数字典
    def get_wapper_key(key, add_s):
        # str.split('.', 1) # 从左到右只分割一次,返回两个元素的 list
        start, end = key.split('.', 1)
        wapped_key = start + '_{}.'.format(add_s) + end

        return wapped_key
    #
    rgb_state_dict = {get_wapper_key(k, '1'): v for k, v in rgb_pretrained_dict.items() if
                      get_wapper_key(k, '1') in model_dict.keys()}
    op_state_dict = {get_wapper_key(k, '2'): v for k, v in op_pretrained_dict.items() if
                     get_wapper_key(k, '2') in model_dict.keys()}
    #
    # update必不可少，实现相同key的value同步
    model_dict.update(rgb_state_dict)
    model_dict.update(op_state_dict)
    # 加载模型部分参数
    model.load_state_dict(model_dict)

    logger.info('load model from multi_pretain file-{},{} successfully!'.format(
        rgb_model_path, op_model_path))
    #
    return model, 0 # g_step
#
def loader_rgb_op_branch(model, rgb_model_path, op_model_path, logger=None):
    # load generator pretrain model, but discriminator ? (TODO)
    # 获取现有模型的参数字典
    rgb_pretrained_dict = torch.load(rgb_model_path, map_location="cuda:0")
    op_pretrained_dict = torch.load(op_model_path, map_location="cuda:0")
    model_dict = model.state_dict()

    # 获取两个模型相同网络层的参数字典
    def get_wapper_key(prefix, key):
        wapped_key = prefix + '.' + key

        return wapped_key

    rgb_state_dict = {get_wapper_key("rgb", k): v for k, v in rgb_pretrained_dict.items() if
                      get_wapper_key("rgb", k) in model_dict.keys()}
    op_state_dict = {get_wapper_key("op", k): v for k, v in op_pretrained_dict.items() if
                      get_wapper_key("op", k) in model_dict.keys()} #

    # update必不可少，实现相同key的value同步
    model_dict.update(rgb_state_dict)
    model_dict.update(op_state_dict)
    # 加载模型部分参数
    model.load_state_dict(model_dict)

    logger.info('load model from multi_pretain file: {},{} successfully!'.format(
    rgb_model_path, op_model_path))
    #
    return model, 0  # g_step
#

def save_json(save_path, item):
    # 多process 同时写 会出错，so要加锁(process-level)
    import fcntl, threading
    # id = threading.currentThread().getName()
    if not os.path.exists(save_path):
        data_dict = {}
        data_dict[item[0]] = item[1]
        with open(save_path, "w") as fp: # 创建文件 并直接写
            fcntl.flock(fp.fileno(), fcntl.LOCK_EX)  # 加锁
            json.dump(data_dict, fp)
    else:
        with open(save_path, "r") as fp:  # 先读出原有内容再
            data_dict = json.load(fp)
            data_dict[item[0]] = item[1]
        with open(save_path, "w+") as fp:  # 追加
            fcntl.flock(fp.fileno(), fcntl.LOCK_EX)  # 加锁
            json.dump(data_dict, fp)

    #

def load_json(save_path, key):
    with open(save_path, "r") as fp:
        data_dict = json.load(fp)
    return data_dict[key]

def test_load_save_json(save_path):
    dict = [("key-{}".format(idx),"world-{}".format(idx)) for idx in range(5)]
    print("dict: ", dict)
    for item in dict:
        print("item: ", item)
        save_json(save_path, item)
    with open(save_path, "r") as fp:
        data_dict = json.load(fp)
    keys = list(data_dict.keys())
    print("keys: ", keys)
    for key in keys:
        print(load_json(save_path, key))


def get_vis_tensor(vis_tensor, dataset_type, nrow):

    if dataset_type == "rgb": # or dataset_type == "optical_flow":
        grid = make_grid(vis_tensor, nrow=nrow, normalize=True, range=(-1, 1))  # normalize, (-1,1) -> (0,1)
    elif dataset_type == "op":
        # 先将 value re-normalize
        image_height,image_width = 256, 256
        vis_tensor[:,0,:,:] = vis_tensor[:,0,:,:] * image_height  # (-1,1) -> (-h, h)
        vis_tensor[:,1,:,:] = vis_tensor[:,1,:,:] * image_width
        #
        flow_batch = vis_tensor.permute(0, 2, 3, 1).to('cpu', torch.uint8).numpy()  # [b, h, w, 2]
        flow_vis_batch = batch_flow_to_image(flow_batch)  # [b, h, w, 3]
        tensor = torch.from_numpy(flow_vis_batch)  # [b, h, w, c]
        tensor = tensor.permute(0, 3, 1, 2)  # [b, c, h, w]
        grid = make_grid(tensor, nrow=nrow)  # (0,1), 无需 normalize
    else:
        grid = None
        print("dataset_type error ! ")
        exit()
    return grid


# for model
def weights_init_normal(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm2d') != -1:
        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)
        torch.nn.init.constant_(m.bias.data, 0.0)


# load ckpt TODO modify (支持断点重训)
def init_model(generator, discriminator,
               generator_model_dir=None, discriminator_model_dir=None,
               logger=None, ):
    g_step_g = 0
    generator.apply(weights_init_normal)
    if discriminator:
        discriminator.apply(weights_init_normal)
    # else:
    #     generator, g_step_g = loader(generator, generator_model_dir
    #                         , logger)
    #     if discriminator:
    #         discriminator, g_step_d = loader(discriminator,
    #                                 discriminator_model_dir, logger)
    #         assert g_step_g == g_step_d, "{} != {} g_step error".format(g_step_g,
    #                                                                    g_step_d)
    logger.info("model init finish!")

    return generator, discriminator, g_step_g


def load_params(exp_tag_params_map_file, exp_tag):

    # (1) load params_save_path from json
    with open(exp_tag_params_map_file, "r") as fp:
        data_dict = json.load(fp)
        params_save_path = data_dict[exp_tag]

    # (2) load params from pickle
    with open(params_save_path, 'rb') as fp:
        params_obj = pickle.load(fp)

    return params_obj


def load_params_test(params_save_path):
    with open(params_save_path, 'rb') as fp:
        params_obj = pickle.load(fp)

    return params_obj


def save_params(params, params_save_path, exp_tag, exp_tag_params_map_file):
    import fcntl, threading

    # (1) pickle, save model to disk; (方便，其实也可以 save __init__参数，再new一个model)
    with open(params_save_path, 'wb') as fp:
        fcntl.flock(fp.fileno(), fcntl.LOCK_EX)  # 加锁
        pickle.dump(params, fp, pickle.HIGHEST_PROTOCOL)

    # (2)json, exp_tag => cur_model_save_path;
    if not os.path.exists(exp_tag_params_map_file):
        data_dict = {}
        data_dict[exp_tag] = params_save_path
        with open(exp_tag_params_map_file, "w") as fp: # 创建文件 并直接写
            fcntl.flock(fp.fileno(), fcntl.LOCK_EX)  # 加锁
            json.dump(data_dict, fp)
    else:
        with open(exp_tag_params_map_file, "r") as fp:  # 先读出原有内容再
            data_dict = json.load(fp)
            data_dict[exp_tag] = params_save_path
        #
        with open(exp_tag_params_map_file, "w+") as fp:  # 追加
            fcntl.flock(fp.fileno(), fcntl.LOCK_EX)  # 加锁
            json.dump(data_dict, fp)


# ============= unit test
if __name__ == '__main__':
    save_path = "/p300/test_dir/test.json"
    test_load_save_json(save_path)


# def test_ssim_error():
#
#     import tensorflow as tf
#
#     img1 = ""  # /p300, a negtive pair and positive pair
#     img2 = ""
#
#     # compare with tf.ssim_error
#     gt_tf, gen_tf = "", ""
#     print(tf.reduce_mean(tf.image.ssim(gt_tf, gen_tf, 2.0)))
#
#     gt_torch, gen_torch = "", ""
#     print(ssim_error(img1, img2))
